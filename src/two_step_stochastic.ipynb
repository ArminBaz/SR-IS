{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd45692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import sem\n",
    "import gymnasium as gym\n",
    "\n",
    "import gym_env\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import decision_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba6071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start state: 0\n",
      "After action 0: state=1, done=0\n",
      "After action 1: state=4, done=1, transition=common\n"
     ]
    }
   ],
   "source": [
    "class TwoStepStochastic:\n",
    "    def __init__(self, size=7, prob_common=0.5, seed=None, stoch_states={1}):\n",
    "        \"\"\"\n",
    "        Two-step task environment with stochastic transitions.\n",
    "        \n",
    "        Args:\n",
    "            size: Number of states\n",
    "            prob_common: Probability of common transition (default 0.5)\n",
    "            seed: Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.size = size\n",
    "        self.prob_common = prob_common\n",
    "        self.rng = np.random.RandomState(seed)\n",
    "        \n",
    "        self.envstep = self._build_transition_table()\n",
    "        self.stochastic_states = stoch_states\n",
    "        \n",
    "    def _build_transition_table(self):\n",
    "        \"\"\"Build the base transition lookup table.\"\"\"\n",
    "        envstep = []\n",
    "        for s in range(self.size):\n",
    "            envstep.append([[0, 0], [0, 0]])\n",
    "        envstep = np.array(envstep)\n",
    "        \n",
    "        # State 0 -> 1, 2 (deterministic)\n",
    "        envstep[0, 0] = [1, 0]\n",
    "        envstep[0, 1] = [2, 0]\n",
    "        \n",
    "        # State 1 -> 3, 4 (will be stochastic)\n",
    "        envstep[1, 0] = [3, 1]  # common for action 0\n",
    "        envstep[1, 1] = [4, 1]  # common for action 1\n",
    "        \n",
    "        # State 2 -> 5, 6 (not stochastic)\n",
    "        envstep[2, 0] = [5, 1]  # common for action 0\n",
    "        envstep[2, 1] = [6, 1]  # common for action 1\n",
    "        \n",
    "        return envstep\n",
    "        \n",
    "    def step_deterministic(self, state, action):\n",
    "        state, done = self.envstep[state, action]\n",
    "        return state, done\n",
    "\n",
    "    def step(self, state, action):\n",
    "        # Get the \"common\" transition for this action\n",
    "        common_state, done = self.envstep[state, action]\n",
    "        \n",
    "        # Handle stochastic transitions\n",
    "        if state in self.stochastic_states:\n",
    "            if self.rng.random() < self.prob_common:\n",
    "                # Common transition\n",
    "                next_state = common_state\n",
    "            else:\n",
    "                # Rare transition (flip to the other action's common state)\n",
    "                rare_action = 1 - action\n",
    "                next_state = self.envstep[state, rare_action][0]\n",
    "        else:\n",
    "            # Deterministic transition\n",
    "            next_state = common_state\n",
    "            \n",
    "        return next_state, done\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset to initial state.\"\"\"\n",
    "        return 0\n",
    "    \n",
    "    def get_transition_type(self, state, action, next_state):\n",
    "        if state not in self.stochastic_states:\n",
    "            return 'deterministic'\n",
    "        \n",
    "        common_state = self.envstep[state, action][0]\n",
    "        if next_state == common_state:\n",
    "            return 'common'\n",
    "        else:\n",
    "            return 'rare'\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    env = TwoStepStochastic(size=7, prob_common=0.5)\n",
    "    \n",
    "    state = env.reset()\n",
    "    print(f\"Start state: {state}\")\n",
    "    \n",
    "    # First step\n",
    "    action = 0\n",
    "    state, done = env.step(state, action)\n",
    "    print(f\"After action {action}: state={state}, done={done}\")\n",
    "    \n",
    "    # Second step\n",
    "    action = 1\n",
    "    next_state, done = env.step(state, action)\n",
    "    transition_type = env.get_transition_type(state, action, next_state)\n",
    "    print(f\"After action {action}: state={next_state}, done={done}, transition={transition_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2131466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SR_IS_TwoStep:\n",
    "    def __init__(self, alpha=0.25, beta=1.0, _lambda=1, num_steps=250, policy=\"softmax\", imp_samp=True, seed=None):\n",
    "        # Hard code start and end locations as well as size\n",
    "        self.start_loc = 0\n",
    "        self.target_locs = [3,4,5,6]\n",
    "        self.start_locs = [0]\n",
    "        self.size = 7\n",
    "        self.agent_loc = self.start_loc\n",
    "        self.seed = seed\n",
    "\n",
    "        # Construct the transition probability matrix and env\n",
    "        self.T = self.construct_T()\n",
    "        self.env = TwoStepStochastic(size=7, prob_common=0.5, seed=self.seed)\n",
    "        \n",
    "        # Get terminal states\n",
    "        self.terminals = np.diag(self.T) == 1\n",
    "        # Calculate P = T_{NT}\n",
    "        self.P = self.T[~self.terminals][:,self.terminals]\n",
    "\n",
    "        # Set reward\n",
    "        self.reward_nt = -0.1\n",
    "        self.r = np.full(len(self.T), self.reward_nt)\n",
    "        # Reward of terminal states depends on if we are replicating reward revaluation or policy revaluation\n",
    "        self.r[self.terminals] = [5,-5,0,1]\n",
    "\n",
    "        # Precalculate exp(r) for use with LinearRL equations\n",
    "        self.expr_t = np.exp(self.r[self.terminals] / _lambda)\n",
    "        self.expr_nt = np.exp(self.reward_nt / _lambda)\n",
    "\n",
    "        # Params\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = self.expr_nt\n",
    "        self._lambda = _lambda\n",
    "        self.num_steps = num_steps\n",
    "        self.policy = policy\n",
    "        self.imp_samp = imp_samp\n",
    "\n",
    "        # Model\n",
    "        self.DR = self.get_DR()\n",
    "        self.Z = np.full(self.size, 0.01)\n",
    "\n",
    "        self.V = np.zeros(self.size)\n",
    "        self.one_hot = np.eye(self.size)\n",
    "\n",
    "    def construct_T(self):\n",
    "        # For two-step task\n",
    "        T = np.zeros((self.size, self.size))\n",
    "        T[0, 1:3] = 0.5\n",
    "        T[1, 3:5] = 0.5\n",
    "        T[2, 5:7] = 0.5\n",
    "        T[3:7, 3:7] = np.eye(4)\n",
    "\n",
    "        return T\n",
    "\n",
    "    def get_DR(self):\n",
    "        if self.policy == \"softmax\":\n",
    "            DR = np.full((self.size, self.size), 0.01)\n",
    "            np.fill_diagonal(DR, 1)\n",
    "            DR[np.where(self.terminals)[0], np.where(self.terminals)[0]] = (1/(self.gamma))\n",
    "        else:\n",
    "            DR = np.eye(self.size)\n",
    "\n",
    "        return DR\n",
    "\n",
    "    def update_Z(self):\n",
    "        self.Z[~self.terminals] = self.DR[~self.terminals][:,~self.terminals] @ self.P @ self.expr_t\n",
    "        self.Z[self.terminals] = self.expr_t\n",
    "\n",
    "    def update_V(self):\n",
    "        self.V = np.log(self.Z) * self._lambda\n",
    "    \n",
    "    def get_successor_states(self, state):\n",
    "        return np.where(self.T[state, :] != 0)[0]\n",
    "\n",
    "    def importance_sampling(self, state, s_prob):\n",
    "        successor_states = self.get_successor_states(state)\n",
    "        p = 1/len(successor_states)\n",
    "        w = p/s_prob\n",
    "                \n",
    "        return w\n",
    "\n",
    "    def select_action(self, state):\n",
    "        if self.policy == \"random\":\n",
    "            action = np.random.choice([0,1])\n",
    "\n",
    "            return action\n",
    "        \n",
    "        elif self.policy == \"softmax\":\n",
    "            successor_states = self.get_successor_states(state)\n",
    "            action_probs = np.full(2, 0.0)   # We can hardcode this because every state has 2 actions\n",
    "\n",
    "            v_sum = sum(np.exp((np.log(self.Z[s] + 1e-20) * self._lambda) / self.beta) for s in successor_states)\n",
    "\n",
    "            # if we don't have enough info, random action\n",
    "            if v_sum == 0:\n",
    "                return  np.random.choice([0,1])\n",
    "\n",
    "            for action in [0,1]:\n",
    "                new_state, _ = self.env.step_deterministic(state, action)\n",
    "                action_probs[action] = np.exp((np.log(self.Z[new_state] + 1e-20) * self._lambda) / self.beta ) / v_sum\n",
    "                \n",
    "            action = np.random.choice([0,1], p=action_probs)\n",
    "            s_prob = action_probs[action]\n",
    "\n",
    "            return action, s_prob\n",
    "\n",
    "    def get_D_inv(self):\n",
    "        I = np.eye(self.size)\n",
    "        D_inv = np.linalg.inv(I-self.gamma*self.T)\n",
    "        \n",
    "        return D_inv\n",
    "\n",
    "    def learn(self):\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(seed=self.seed)\n",
    "\n",
    "        for i in range(self.num_steps):\n",
    "            # Agent gets some knowledge of terminal state values\n",
    "            if i == 2:\n",
    "                self.Z[self.terminals] = self.expr_t\n",
    "            state = self.agent_loc\n",
    "\n",
    "            if self.policy == \"softmax\":\n",
    "                action, s_prob = self.select_action(state)\n",
    "            else:\n",
    "                action = self.select_action(state)\n",
    "        \n",
    "            next_state, done = self.env.step(state, action)\n",
    "\n",
    "            if self.imp_samp:\n",
    "                w = self.importance_sampling(state, s_prob)\n",
    "                w = 1 if np.isnan(w) or w == 0 else w\n",
    "            else:\n",
    "                w = 1\n",
    "            \n",
    "            target = self.one_hot[state] + self.gamma * self.DR[next_state]\n",
    "            self.DR[state] = (1 - self.alpha) * self.DR[state] + self.alpha * target * w\n",
    "\n",
    "            self.Z[~self.terminals] = self.DR[~self.terminals][:,~self.terminals] @ self.P @ self.expr_t\n",
    "            \n",
    "            # print(f\"state: {state}| action: {action}| next state: {next_state}\")\n",
    "            \n",
    "            if done:\n",
    "                self.agent_loc = self.start_loc\n",
    "                continue\n",
    "            \n",
    "            # Update state\n",
    "            state = next_state\n",
    "            self.agent_loc = state\n",
    "\n",
    "        # Update DR at terminal state\n",
    "        self.update_Z()\n",
    "        self.update_V()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "540233ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_val = 1\n",
    "lambd = set_val\n",
    "alpha = 0.1\n",
    "alpha = 0.05\n",
    "beta = set_val\n",
    "num_steps = 250\n",
    "num_seeds = 500\n",
    "\n",
    "prob_s2 = []\n",
    "prob_s3 = []\n",
    "\n",
    "for i in range(num_seeds):\n",
    "    seed = int(i)\n",
    "    agent =  SR_IS_TwoStep(_lambda=lambd, alpha=alpha, beta=beta, num_steps=num_steps, policy=\"softmax\", imp_samp=True, seed=seed)\n",
    "    agent.learn()\n",
    "    pii = decision_policy(agent, agent.Z)\n",
    "    prob_s2.append(pii[0,1])\n",
    "    prob_s3.append(pii[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84361f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean prob of S2: (0.9361234328426873, 0.0002928396469857265) | Mean prob of S3: (0.0638765671573127, 0.00029283964698572637)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean prob of S2: ({np.mean(prob_s2)}, {sem(prob_s2)}) | Mean prob of S3: ({np.mean(prob_s3)}, {sem(prob_s3)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec655f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot values\n",
    "means = [np.mean(prob_s2), np.mean(prob_s3)]\n",
    "std = [sem(prob_s2), sem(prob_s3)]\n",
    "\n",
    "save_dir = os.path.join('..', 'figures/')\n",
    "save_path = save_dir + \"TwoStepStochastic_SR-IS.png\"\n",
    "# save_path = None\n",
    "colors = [9, 1]\n",
    "\n",
    "title = \"SR-IS\"\n",
    "xlabels = [\"State 2\", \"State 3\"]\n",
    "y_lim = None\n",
    "ylabel = \"Probability\"\n",
    "\n",
    "# Plot\n",
    "color_palette = sns.color_palette(\"colorblind\")\n",
    "color_list = []\n",
    "for color in colors:\n",
    "    color_list.append(color_palette[color])\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "x = np.arange(len(means)) * 0.25\n",
    "\n",
    "plot_means = np.array(means, dtype=float).copy()\n",
    "min_visible_height = 0.025\n",
    "plot_means[plot_means < 0.1] = min_visible_height\n",
    "\n",
    "bars = ax.bar(x, plot_means, color=color_list, edgecolor='black', linewidth=1, width=0.14)\n",
    "\n",
    "if std is not None:\n",
    "    ax.errorbar(x, means, yerr=std, fmt='none', color='black', capsize=0)\n",
    "\n",
    "ax.set_ylabel(ylabel, fontsize=18)\n",
    "ax.set_title(title, fontsize=20) if title else None\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(xlabels, rotation=0, ha='center', fontsize=18)\n",
    "\n",
    "if y_lim is None:\n",
    "    ax.set_yticks(np.arange(0, 1.01, 0.2))\n",
    "    ax.set_ylim(0, 1.1)\n",
    "else:\n",
    "    ax.set_yticks(np.arange(y_lim[0], y_lim[1], 0.2))\n",
    "    ax.set_ylim(y_lim[0], y_lim[1])\n",
    "\n",
    "# for spine in ['left', 'right', 'bottom', 'top']:\n",
    "#     ax.spines[spine].set_color('black')\n",
    "#     ax.spines[spine].set_linewidth(1)\n",
    "\n",
    "for spine in ['right', 'top']:\n",
    "    ax.spines[spine].set_linewidth(0)\n",
    "\n",
    "ax.grid(False)\n",
    "\n",
    "ax.set_facecolor('white')\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_path:\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5b8b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# # Get the colorblind palette\n",
    "# colorblind_palette = sns.color_palette(\"colorblind\")\n",
    "\n",
    "# print(\"Seaborn Colorblind Palette RGB Values:\")\n",
    "# print(\"=\" * 50)\n",
    "\n",
    "# for i, color in enumerate(colorblind_palette):\n",
    "#     # Convert from 0-1 range to 0-255 range\n",
    "#     r = int(color[0] * 255)\n",
    "#     g = int(color[1] * 255)\n",
    "#     b = int(color[2] * 255)\n",
    "    \n",
    "#     print(f\"Color {i}: RGB({r:3d}, {g:3d}, {b:3d}) | Normalized: ({color[0]:.3f}, {color[1]:.3f}, {color[2]:.3f})\")\n",
    "\n",
    "# print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5ccb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
